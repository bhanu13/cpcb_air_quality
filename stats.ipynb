{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "- http://www.cpcb.gov.in/CAAQM/frmUserAvgReportCriteria.aspx\n",
    "- http://www.cpcb.gov.in/CAAQM/mapPage/frmindiamap.aspx\n",
    "\n",
    "### Make Use of Beautiful Soup to automate fetching data\n",
    "- Historic Annual PM2.5, PM10 Plot\n",
    "    - INDIA - National\n",
    "    - Delhi NCR\n",
    "    - Delhi Location wise\n",
    "    - Gurgaon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Mechanize Links:\n",
    "   - http://www.search.sourceforge.net/mechanize/\n",
    "   - Forms Example: http://www.search.sourceforge.net/mechanize/forms.html\n",
    "   - BSoup Input Parsing: http://stackoverflow.com/questions/23001678/python-beautiful-soup-form-input-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import mechanize\n",
    "import re\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.cpcb.gov.in/CAAQM/frmUserAvgReportCriteria.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOptions(param, form):\n",
    "    return re.findall(\"{}=\\[(.+)\\]\".format(param), str(form))\n",
    "\n",
    "def getStations(ddlState, ddlCity):\n",
    "    br = mechanize.Browser()\n",
    "    br.set_handle_robots(False)\n",
    "    res = br.open(url)\n",
    "    forms = mechanize.ParseResponse(res, backwards_compat=False)\n",
    "    form = forms[0]\n",
    "    # State\n",
    "    form[\"ddlState\"] = [\"{}\".format(ddlState),]\n",
    "    form, html = updateForm(br, form)\n",
    "    # City\n",
    "    form[\"ddlCity\"] = [\"{}\".format(ddlCity),]\n",
    "    form, html = updateForm(br, form)\n",
    "    \n",
    "    options = getOptions(\"ddlStation\", form)\n",
    "    options = options[0].split(',')[1:]\n",
    "    options = map(lambda x: x.strip(), options)\n",
    "    stations = options\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     Example Usage: \n",
    "#     soup = BeautifulSoup(html)\n",
    "#     getMap(soup, \"ddlState\")\n",
    "def getMap(soup, ty):\n",
    "    select_node = soup.findAll('select', attrs={'name': ty})\n",
    "    if not select_node:\n",
    "        select_node = soup.findAll('select', attrs={'id': ty})\n",
    "#     print select_node\n",
    "    option_map = {}\n",
    "    if select_node:\n",
    "        for option in select_node[0].findAll('option'):\n",
    "            option_map[option['value']] = option.text\n",
    "    return option_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSleepTime = 2.0\n",
    "def randSleepTime():\n",
    "    return (1.0 + random.random() * maxSleepTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPM25Id(html):\n",
    "    return re.findall(\"<option value=(.+)>(.*)PM2\\.5(.*)</option>\", str(html))\n",
    "\n",
    "def getData(state, city):\n",
    "    # Delhi, Delhi\n",
    "#     state, city = \"6\", \"85\"\n",
    "    stations = getStations(state, city)\n",
    "    soups = []\n",
    "    #\n",
    "    random.shuffle(stations)\n",
    "    for station in stations:\n",
    "        try:\n",
    "            br = mechanize.Browser()\n",
    "            br.addheaders = [('user-agent', \n",
    "            '   Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.2.3) Gecko/20100423 Ubuntu/10.04 (lucid) Firefox/3.6.3'),\n",
    "            ('accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8')]\n",
    "\n",
    "            br.set_handle_robots(False)\n",
    "            res = br.open(url)\n",
    "\n",
    "            forms = mechanize.ParseResponse(res, backwards_compat=False)\n",
    "            form = forms[0]\n",
    "\n",
    "            form[\"ddlState\"] = [state,]\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            form[\"ddlCity\"] = [city,]\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            form[\"ddlStation\"] = [\"{}\".format(station),]\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "    #         print html\n",
    "            parsed_pm25 = getPM25Id(html)\n",
    "            if parsed_pm25:\n",
    "                PM25Id = getPM25Id(html)[0][0][1:-1]\n",
    "                print \"PM2.5 Id =\", PM25Id\n",
    "            else:\n",
    "                print \"No PM2.5 for {}, {}, {}\".format(state, city, station)\n",
    "                continue\n",
    "\n",
    "            form[\"lstBoxChannelLeft\"] = [\"{}\".format(PM25Id),]\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            form[\"ddlCriteria\"] = [\"0\",]\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            form[\"txtYear\"] = \"2000\"\n",
    "            form[\"txtYearTo\"] = \"2017\"\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            form[\"btnSubmit\"] = \"True\"\n",
    "            form, html = updateForm(br, form)\n",
    "\n",
    "            br.select_form(\"form1\")\n",
    "\n",
    "            time.sleep(randSleepTime())\n",
    "            res = br.submit(name='btnSubmit')\n",
    "            html = res.read()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            soups.append([(state, city, station), soup])\n",
    "    #         if len(soups) >= 2:\n",
    "    #             break\n",
    "            time.sleep(randSleepTime())\n",
    "            br.close()\n",
    "            print \"Finished Crawling for {}, {}, {}\".format(state, city, station)\n",
    "\n",
    "        except:\n",
    "            print \"Exception raised for {}, {}, {}\".format(state, city, station)\n",
    "            time.sleep(5)\n",
    "            br.close()\n",
    "            continue\n",
    "            \n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateForm(br, form):\n",
    "    time.sleep(randSleepTime())\n",
    "    res = br.open(form.click())\n",
    "    html = res.get_data()\n",
    "    forms = mechanize.ParseResponse(res, backwards_compat=False)\n",
    "    form = forms[0]\n",
    "    return form, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getValsHtml(table):\n",
    "    data = []\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    vals = re.findall(\"\\d+\\.\\d+\", data[0][0])[:-1]\n",
    "    data = []\n",
    "    for val in vals:\n",
    "        yr = val[:4]\n",
    "        data.append([yr, val[4:]])\n",
    "    return data\n",
    "\n",
    "def cleanupData(data):\n",
    "    clean_data = []\n",
    "    for elem in data:\n",
    "        if elem[0] in map(str, range(2000, 2018)):\n",
    "            clean_data.append(elem)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('city-ids.txt', 'r')\n",
    "cities = f.readlines()\n",
    "cities = map(lambda elem: elem.split(\",\"), cities)[1:]\n",
    "cities = map(lambda elem: [elem[0], elem[1], elem[2], elem[3][:-1]], cities)\n",
    "cities = filter(lambda elem: elem[2].isdigit(), cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM2.5 Id = 1373\n",
      "Finished Crawling for 25, 546, 8\n",
      "PM2.5 Id = 1374\n",
      "Finished Crawling for 25, 546, 9\n",
      "PM2.5 Id = 1375\n",
      "Finished Crawling for 25, 546, 33\n",
      "---\n",
      "Finished Crawling city Tamil Nadu, Chennai\n",
      "No PM2.5 for 22, 194, 103\n",
      "---\n",
      "Finished Crawling city Punjab, Ludhiana\n",
      "PM2.5 Id = 1886\n",
      "Finished Crawling for 22, 188, 102\n",
      "---\n",
      "Finished Crawling city Punjab, Amritsar\n",
      "PM2.5 Id = 1893\n",
      "Finished Crawling for 22, 553, 106\n",
      "---\n",
      "Finished Crawling city Punjab, Mandi Gobindgarh\n",
      "PM2.5 Id = 1536\n",
      "Finished Crawling for 23, 212, 85\n",
      "---\n",
      "Finished Crawling city Rajasthan, Jodhpur\n",
      "PM2.5 Id = 1500\n",
      "Finished Crawling for 23, 223, 83\n",
      "---\n",
      "Finished Crawling city Rajasthan, Jaipur\n",
      "PM2.5 Id = 1632\n",
      "Finished Crawling for 28, 278, 38\n",
      "---\n",
      "Finished Crawling city Uttar Pradesh, Kanpur\n",
      "PM2.5 Id = 1383\n",
      "Finished Crawling for 28, 253, 39\n",
      "PM2.5 Id = 1086\n",
      "Finished Crawling for 28, 253, 21\n",
      "---\n",
      "Finished Crawling city Uttar Pradesh, Agra\n",
      "PM2.5 Id = 1379\n",
      "Finished Crawling for 28, 270, 40\n",
      "---\n",
      "Finished Crawling city Uttar Pradesh, Varanasi\n",
      "PM2.5 Id = 1369\n",
      "Finished Crawling for 28, 256, 12\n",
      "PM2.5 Id = 1368\n",
      "Finished Crawling for 28, 256, 11\n",
      "PM2.5 Id = 1367\n",
      "Finished Crawling for 28, 256, 10\n",
      "---\n",
      "Finished Crawling city Uttar Pradesh, Lucknow\n",
      "No PM2.5 for 29, 300, 35\n",
      "PM2.5 Id = 1599\n",
      "Finished Crawling for 29, 300, 31\n",
      "PM2.5 Id = 1638\n",
      "Finished Crawling for 29, 300, 92\n",
      "---\n",
      "Finished Crawling city West Bengal, Kolkata\n",
      "PM2.5 Id = 1734\n",
      "Finished Crawling for 29, 548, 88\n",
      "---\n",
      "Finished Crawling city West Bengal, Howrah\n",
      "PM2.5 Id = 1590\n",
      "Finished Crawling for 29, 549, 82\n",
      "---\n",
      "Finished Crawling city West Bengal, Haldia\n",
      "No PM2.5 for 29, 552, 98\n",
      "---\n",
      "Finished Crawling city West Bengal, Durgapur\n",
      "PM2.5 Id = 1702\n",
      "Finished Crawling for 1, 9, 95\n",
      "---\n",
      "Finished Crawling city Andhra Pradesh, Visakhapatnam\n",
      "PM2.5 Id = 1721\n",
      "Finished Crawling for 1, 21, 96\n",
      "---\n",
      "Finished Crawling city Andhra Pradesh, Tirupati\n",
      "PM2.5 Id = 1465\n",
      "Finished Crawling for 4, 54, 81\n",
      "---\n",
      "Finished Crawling city Bihar, Muzaffarpur\n",
      "PM2.5 Id = 1610\n",
      "Finished Crawling for 4, 75, 90\n",
      "---\n",
      "Finished Crawling city Bihar, Gaya\n",
      "PM2.5 Id = 1334\n",
      "Finished Crawling for 4, 70, 65\n",
      "---\n",
      "Finished Crawling city Bihar, Patna\n",
      "PM2.5 Id = 1378\n",
      "Finished Crawling for 6, 85, 5\n",
      "PM2.5 Id = 508\n",
      "Finished Crawling for 6, 85, 3\n",
      "PM2.5 Id = 7\n",
      "Finished Crawling for 6, 85, 47\n",
      "PM2.5 Id = 509\n",
      "Finished Crawling for 6, 85, 4\n",
      "PM2.5 Id = 1376\n",
      "Finished Crawling for 6, 85, 7\n",
      "PM2.5 Id = 513\n",
      "Finished Crawling for 6, 85, 45\n",
      "PM2.5 Id = 507\n",
      "Finished Crawling for 6, 85, 2\n",
      "No PM2.5 for 6, 85, 51\n",
      "No PM2.5 for 6, 85, 55\n",
      "PM2.5 Id = 514\n",
      "Finished Crawling for 6, 85, 46\n",
      "PM2.5 Id = 1377\n",
      "Finished Crawling for 6, 85, 6\n",
      "PM2.5 Id = 506\n",
      "Finished Crawling for 6, 85, 1\n",
      "PM2.5 Id = 1290\n",
      "Finished Crawling for 6, 85, 52\n",
      "PM2.5 Id = 1316\n",
      "Exception raised for 6, 85, 53\n",
      "No PM2.5 for 6, 85, 58\n",
      "PM2.5 Id = 1341\n",
      "Finished Crawling for 6, 85, 54\n",
      "---\n",
      "Finished Crawling city Delhi, Delhi\n",
      "PM2.5 Id = 1589\n",
      "Finished Crawling for 9, 364, 86\n",
      "---\n",
      "Finished Crawling city Haryana, Gurgaon\n",
      "PM2.5 Id = 1384\n",
      "Finished Crawling for 9, 365, 34\n",
      "---\n",
      "Finished Crawling city Haryana, Faridabad\n",
      "PM2.5 Id = 1588\n",
      "Finished Crawling for 9, 348, 84\n",
      "---\n",
      "Finished Crawling city Haryana, Panchkula\n",
      "PM2.5 Id = 1629\n",
      "Finished Crawling for 9, 360, 91\n",
      "---\n",
      "Finished Crawling city Haryana, Rohtak\n",
      "PM2.5 Id = 1187\n",
      "Finished Crawling for 8, 337, 41\n",
      "---\n",
      "Finished Crawling city Gujarat, Ahmedabad\n",
      "PM2.5 Id = 1372\n",
      "Finished Crawling for 13, 136, 16\n",
      "No PM2.5 for 13, 136, 24\n",
      "No PM2.5 for 13, 136, 25\n",
      "PM2.5 Id = 1371\n",
      "Finished Crawling for 13, 136, 15\n",
      "PM2.5 Id = 1370\n",
      "Finished Crawling for 13, 136, 14\n",
      "---\n",
      "Finished Crawling city Karnataka, Bengaluru\n",
      "PM2.5 Id = 1751\n",
      "Finished Crawling for 16, 308, 97\n",
      "---\n",
      "Finished Crawling city Maharashtra, Aurangabad\n",
      "PM2.5 Id = 1779\n",
      "Finished Crawling for 16, 309, 99\n",
      "---\n",
      "Finished Crawling city Maharashtra, Thane\n",
      "PM2.5 Id = 1401\n",
      "Finished Crawling for 16, 312, 30\n",
      "---\n",
      "Finished Crawling city Maharashtra, Pune\n",
      "PM2.5 Id = 999\n",
      "Finished Crawling for 16, 310, 29\n",
      "PM2.5 Id = 1391\n",
      "Finished Crawling for 16, 310, 27\n",
      "PM2.5 Id = 1357\n",
      "Finished Crawling for 16, 310, 28\n",
      "---\n",
      "Finished Crawling city Maharashtra, Mumbai\n",
      "PM2.5 Id = 1566\n",
      "Finished Crawling for 16, 314, 87\n",
      "---\n",
      "Finished Crawling city Maharashtra, Solapur\n",
      "PM2.5 Id = 1676\n",
      "Finished Crawling for 16, 307, 94\n",
      "---\n",
      "Finished Crawling city Maharashtra, Nashik\n",
      "PM2.5 Id = 1654\n",
      "Finished Crawling for 16, 327, 93\n",
      "---\n",
      "Finished Crawling city Maharashtra, Nagpur\n",
      "PM2.5 Id = 1796\n",
      "Finished Crawling for 16, 329, 100\n",
      "PM2.5 Id = 1427\n",
      "Finished Crawling for 16, 329, 79\n",
      "---\n",
      "Finished Crawling city Maharashtra, Chandrapur\n",
      "PM2.5 Id = 1813\n",
      "Finished Crawling for 30, 7, 101\n",
      "PM2.5 Id = 1380\n",
      "Finished Crawling for 30, 7, 36\n",
      "PM2.5 Id = 1443\n",
      "Finished Crawling for 30, 7, 80\n",
      "PM2.5 Id = 1844\n",
      "Finished Crawling for 30, 7, 104\n",
      "PM2.5 Id = 1863\n",
      "Finished Crawling for 30, 7, 105\n",
      "---\n",
      "Finished Crawling city Telangana, Hyderabad\n"
     ]
    }
   ],
   "source": [
    "for elem in cities:\n",
    "    stateId, stateName, cityId, cityName = elem\n",
    "    f = open('data/{}_{}.txt'.format(stateName, cityName), 'w')\n",
    "    try:\n",
    "        soups = getData(stateId, cityId)\n",
    "        for s in soups:\n",
    "            state, city, station = s[0]\n",
    "            f.write(\"state:{},city:{},station:{}\\n\".format(state, city, station))\n",
    "            html_data = s[1].find(id=\"gvReportStation\")\n",
    "            if html_data:\n",
    "                data = getValsHtml(html_data)\n",
    "                data = cleanupData(data)\n",
    "                for elem in data:\n",
    "                    f.write(','.join(str(x) for x in elem) + \"\\n\")\n",
    "            else:\n",
    "                f.write(\"None\\n\")\n",
    "\n",
    "            f.write(\"\\n\")\n",
    "        f.close()\n",
    "        print \"---\"\n",
    "        print \"Finished Crawling city {}, {}\".format(stateName, cityName)\n",
    "        time.sleep(7) # Sleep for 7 seconds before continuing for next city\n",
    "    except:\n",
    "        print \"Error occurred at {}, {}, {}, {}\".format(stateId, stateName, cityId, cityName)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = getStatesMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM2.5 Id = 1341\n",
      "PM2.5 Id = 508\n",
      "PM2.5 Id = 1378\n",
      "PM2.5 Id = 1290\n",
      "PM2.5 Id = 1377\n",
      "PM2.5 Id = 7\n",
      "PM2.5 Id = 513\n",
      "PM2.5 Id = 1376\n",
      "PM2.5 Id = 507\n",
      "PM2.5 Id = 514\n",
      "No PM2.5 for 6, 85, 58\n",
      "PM2.5 Id = 1316\n",
      "Exception raised for 6, 85, 53\n",
      "No PM2.5 for 6, 85, 51\n",
      "PM2.5 Id = 509\n",
      "PM2.5 Id = 506\n",
      "No PM2.5 for 6, 85, 55\n"
     ]
    }
   ],
   "source": [
    "soups = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('delhi-pm25-data.txt', 'w')\n",
    "for s in soups:\n",
    "    state, city, station = s[0]\n",
    "    f.write(\"state:{},city:{},station:{}\\n\".format(state, city, station))\n",
    "    html_data = s[1].find(id=\"gvReportStation\")\n",
    "    if html_data:\n",
    "        data = getValsHtml(html_data)\n",
    "        data = cleanupData(data)\n",
    "        for elem in data:\n",
    "            f.write(','.join(str(x) for x in elem) + \"\\n\")\n",
    "    else:\n",
    "        f.write(\"None\\n\")\n",
    "    \n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data available for this station\n",
      "[[u'2016', u'216.32'], [u'2017', u'123.35']]\n"
     ]
    }
   ],
   "source": [
    "for soup in soups:\n",
    "    table = soup[1].find(id=\"gvReportStation\")\n",
    "    if table:\n",
    "        data = getValsHtml(table)\n",
    "        data = cleanupData(data)\n",
    "        print data\n",
    "    else:\n",
    "        print \"No Data available for this station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '45', '46', '47', '51', '52', '53', '54', '55', '58']\n"
     ]
    }
   ],
   "source": [
    "print getStations(\"6\", \"85\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bee4641bbbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\d+\\.\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0myr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "vals = re.findall(\"\\d+\\.\\d+\", data[0][0])[:-1]\n",
    "for val in vals:\n",
    "    yr = val[:4]\n",
    "    print yr, val[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
